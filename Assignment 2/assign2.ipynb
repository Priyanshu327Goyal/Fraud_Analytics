{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Dependent Cost Sensitive Classification\n",
    "\n",
    "Team Members\\\n",
    "CS21BTECH11060: Varun Gupta\\\n",
    "MA22BTECH11015: Priyanshu Goyal\\\n",
    "AI22BTECH11020: Pranay Jain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from functools import lru_cache\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "# Load the data\n",
    "df_fraud = pd.read_csv(\"costsensitiveregression.csv\")\n",
    "\n",
    "# Reorder columns: move second-to-last column first, then everything else, then last column\n",
    "cols = df_fraud.columns.tolist()\n",
    "cols = cols[-2:-1] + cols[:-2] + cols[-1:]\n",
    "df_fraud = df_fraud[cols]\n",
    "\n",
    "# Split label (col 0) from features (col 1..end)\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    df_fraud.iloc[:, 1:],  # features\n",
    "    df_fraud.iloc[:, 0],   # label\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Separate out the false negative cost column \"FNC\"\n",
    "cost_train = X_train_full[\"FNC\"]\n",
    "cost_test = X_test_full[\"FNC\"]\n",
    "\n",
    "# Drop the cost column from features\n",
    "X_train_full = X_train_full.drop(\"FNC\", axis=1)\n",
    "X_test_full = X_test_full.drop(\"FNC\", axis=1)\n",
    "\n",
    "# Convert everything to NumPy\n",
    "X_train = X_train_full.to_numpy()\n",
    "X_test = X_test_full.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "cost_train = cost_train.to_numpy()\n",
    "cost_test = cost_test.to_numpy()\n",
    "\n",
    "# Remove or adjust entries where cost_train is zero or negative\n",
    "cost_train[cost_train <= 0] = 0.001  # Small positive value\n",
    "cost_test[cost_test <= 0] = 0.001\n",
    "\n",
    "# Alternatively, remove rows with non-positive values\n",
    "positive_mask_train = cost_train > 0\n",
    "positive_mask_test = cost_test > 0\n",
    "\n",
    "X_train = X_train[positive_mask_train]\n",
    "y_train = y_train[positive_mask_train]\n",
    "cost_train = cost_train[positive_mask_train]\n",
    "\n",
    "X_test = X_test[positive_mask_test]\n",
    "y_test = y_test[positive_mask_test]\n",
    "cost_test = cost_test[positive_mask_test]\n",
    "\n",
    "# Cap the costs at a high but manageable level\n",
    "cost_cap = 100000  # for example, if reasonable\n",
    "cost_train = np.minimum(cost_train, cost_cap)\n",
    "cost_test = np.minimum(cost_test, cost_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(z):\n",
    "    \"\"\"Applies the sigmoid transformation elementwise.\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def compute_inverse_gamma(val):\n",
    "    \"\"\"\n",
    "    Approximate the inverse of the gamma function for a given positive 'val'.\n",
    "    Uses root finding to solve gamma(x) - val = 0 within a bracket.\n",
    "    \"\"\"\n",
    "    def gamma_equation(x, target):\n",
    "        return gamma(x) - target\n",
    "    \n",
    "    # Add a small offset to avoid zero\n",
    "    bracket_result = root_scalar(\n",
    "        gamma_equation, \n",
    "        args=(val + 1e-8,), \n",
    "        bracket=[-1e-18, 100]\n",
    "    )\n",
    "    if not bracket_result.converged:\n",
    "        raise ValueError(\"Inverse gamma could not be computed.\")\n",
    "    return bracket_result.root\n",
    "\n",
    "# @lru_cache(maxsize=1000)\n",
    "# def compute_inv_gamma(val):\n",
    "#     \"\"\"Compute the inverse of the gamma function for a given value, trying with a wider bracket.\"\"\"\n",
    "#     def gamma_eq(x):\n",
    "#         return gamma(x) - val\n",
    "#     result = root_scalar(gamma_eq, bracket=[1e-6, 100], method='brentq')  # Notice the bracket now goes up to 100\n",
    "#     if not result.converged:\n",
    "#         print(f\"Warning: No convergence for value {val}\")\n",
    "#         return None  # Return None or some other indicator of failure\n",
    "#     return result.root\n",
    "\n",
    "# def compute_inv_gamma(val):\n",
    "#     \"\"\"Compute the inverse of the gamma function using a non-bracketing method.\"\"\"\n",
    "#     def gamma_eq(x):\n",
    "#         return gamma(x) - val\n",
    "#     try:\n",
    "#         initial_guess = 2  # Start from a reasonable guess\n",
    "#         result = root_scalar(gamma_eq, x0=initial_guess, x1=initial_guess + 1, method='secant')\n",
    "#         if result.converged:\n",
    "#             return result.root\n",
    "#         else:\n",
    "#             print(f\"Warning: Secant method did not converge for value {val}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error computing inverse gamma for {val}: {e}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import gamma\n",
    "# from scipy.optimize import brentq\n",
    "# import numpy as np\n",
    "\n",
    "# def find_root_of_gamma(target_value, lower_bound=1e-6, upper_bound=10):\n",
    "#     \"\"\"Find x such that gamma(x) is approximately equal to target_value.\"\"\"\n",
    "#     try:\n",
    "#         lower_gamma = gamma(lower_bound)\n",
    "#         upper_gamma = gamma(upper_bound)\n",
    "\n",
    "#         if (lower_gamma - target_value) * (upper_gamma - target_value) > 0:\n",
    "#             print(f\"No root found in bracket for target_value {target_value}\")\n",
    "#             return None\n",
    "\n",
    "#         root = brentq(lambda x: gamma(x) - target_value, lower_bound, upper_bound)\n",
    "#         return root\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error finding root for {target_value}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# root_for_6 = find_root_of_gamma(6)\n",
    "# print(\"Root for Gamma(x) = 6 is approximately:\", root_for_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.special import gamma\n",
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "# # Precompute gamma values\n",
    "# x_values = np.linspace(1, 10, 1000)  # Adjust range and density as needed\n",
    "# gamma_values = gamma(x_values)\n",
    "\n",
    "# # Create an interpolating function\n",
    "# gamma_inverse = interp1d(gamma_values, x_values, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "# # Now you can find gamma inverse for any value within the range of gamma_values\n",
    "# x_for_gamma_6 = gamma_inverse(6)\n",
    "# print(\"x for which Gamma(x) = 6:\", x_for_gamma_6)\n",
    "\n",
    "# from scipy.special import gamma\n",
    "# from scipy.optimize import brentq\n",
    "\n",
    "# def inverse_gamma(value):\n",
    "#     \"\"\"Compute the inverse of the gamma function for a given value using a robust root-finding method.\"\"\"\n",
    "#     lower_bound, upper_bound = 1e-6, 20  # Adjust based on expected range of gamma values\n",
    "#     try:\n",
    "#         return brentq(lambda x: gamma(x) - value, lower_bound, upper_bound)\n",
    "#     except ValueError:\n",
    "#         print(f\"No root found within the bracket for the value {value}\")\n",
    "#         return None  # Handle how you prefer: return None, or use a default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def cost_nikou(true_labels, predictions, fn_cost):\n",
    "#     \"\"\"Calculate the Nikou cost function using inverse gamma calculations.\"\"\"\n",
    "#     fpc = 6  # False positive cost\n",
    "#     preds = np.clip(predictions, 1e-8, 1 - 1e-8)  # Avoid log(0)\n",
    "    \n",
    "#     b_values = np.where(\n",
    "#         true_labels == 1,\n",
    "#         [inverse_gamma(fnc) for fnc in fn_cost],\n",
    "#         inverse_gamma(fpc)\n",
    "#     )\n",
    "    \n",
    "#     a_values = 1.0 / gamma(b_values + 1)\n",
    "#     term1 = true_labels * np.power(-np.log(preds), b_values)\n",
    "#     term2 = (1 - true_labels) * np.power(-np.log(1 - preds), b_values)\n",
    "#     return np.mean(a_values * (term1 + term2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import interp1d\n",
    "# from scipy.special import gamma\n",
    "# import numpy as np\n",
    "\n",
    "# # Precompute gamma values\n",
    "# x_values = np.linspace(1, 20, 5000)  # Choose an appropriate range and resolution\n",
    "# gamma_values = gamma(x_values)\n",
    "# gamma_inv = interp1d(gamma_values, x_values, kind='linear', fill_value=\"extrapolate\", bounds_error=False)\n",
    "\n",
    "# def cost_nikou(true_labels, predictions, fn_cost):\n",
    "#     \"\"\"Calculate the Nikou cost function using a precomputed interpolation for inverse gamma.\"\"\"\n",
    "#     fpc = 6\n",
    "#     preds = np.clip(predictions, 1e-8, 1 - 1e-8)  # Avoid log(0)\n",
    "    \n",
    "#     b_values = np.where(\n",
    "#         true_labels == 1,\n",
    "#         gamma_inv(fn_cost),  # Apply interpolated inverse gamma function\n",
    "#         gamma_inv(fpc)\n",
    "#     )\n",
    "    \n",
    "#     a_values = 1.0 / gamma(b_values + 1)\n",
    "#     term1 = true_labels * np.power(-np.log(preds), b_values)\n",
    "#     term2 = (1 - true_labels) * np.power(-np.log(1 - preds), b_values)\n",
    "#     return np.mean(a_values * (term1 + term2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_bahnsen_approach(true_labels, predictions, fn_cost):\n",
    "    \"\"\"\n",
    "    Bahnsen cost function:\n",
    "    - true positive cost (tpc) = 6\n",
    "    - false positive cost (fpc) = 6\n",
    "    - true negative cost (tnc) = 0\n",
    "    - false negative cost (fnc) is row-dependent (fn_cost).\n",
    "    \n",
    "    Note: 'predictions' are the sigmoid outputs, not 0/1 classes.\n",
    "    \"\"\"\n",
    "    tpc = 6\n",
    "    fpc = 6\n",
    "    tnc = 0\n",
    "    # The formula here uses predictions in place of 'h(x)'\n",
    "    # y * [h(x)*TP + (1 - h(x))*FN] + (1 - y) * [h(x)*FP + (1 - h(x))*TN]\n",
    "    # However, there's a slight mismatch: it uses (1 - y_pred) again in the second term,\n",
    "    # so it effectively lumps them. We'll keep the structure for equivalence.\n",
    "    combined_loss = (\n",
    "        true_labels * (predictions * tpc + (1.0 - predictions) * fn_cost)\n",
    "        + (1.0 - predictions) * (predictions * fpc + (1.0 - predictions) * tnc)\n",
    "    )\n",
    "    return np.mean(combined_loss)\n",
    "\n",
    "\n",
    "def cost_nikou_approach(true_labels, predictions, fn_cost):\n",
    "    \"\"\"\n",
    "    Vectorized Nikou cost function.\n",
    "    For each sample, compute:\n",
    "      b = (1 - y)*inverse_gamma(fpc) + y*inverse_gamma(fn_cost)\n",
    "      a = 1 / Gamma(b + 1)\n",
    "      Loss = a*y*(-log(pred))^b + a*(1-y)*(-log(1-pred))^b\n",
    "    \"\"\"\n",
    "    fpc = 6\n",
    "    preds = np.clip(predictions, 1e-8, 1 - 1e-8)\n",
    "    \n",
    "    try:\n",
    "        inv_gamma_value = compute_inverse_gamma(fpc)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compute inverse gamma for value {fpc}: {str(e)}\")\n",
    "\n",
    "    # Precompute inverse gamma for fpc since it's constant\n",
    "    inv_gamma_fpc = compute_inverse_gamma(fpc)\n",
    "\n",
    "    # Vectorize inverse gamma for the row-specific fn_cost values\n",
    "    vec_inv_gamma = np.vectorize(compute_inverse_gamma)\n",
    "    b_vals = np.where(true_labels == 1, vec_inv_gamma(fn_cost), inv_gamma_fpc)\n",
    "    \n",
    "    a_vals = 1.0 / gamma(b_vals + 1.0)\n",
    "    term1 = true_labels * np.power(-np.log(preds), b_vals)\n",
    "    term2 = (1.0 - true_labels) * np.power(-np.log(1 - preds), b_vals)\n",
    "    return np.mean(a_vals * (term1 + term2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic Algorithm Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(pop, X, y, fn_cost, cost_func):\n",
    "    \"\"\"\n",
    "    Fitness = 1 / (1 + cost), so lower cost => higher fitness.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for individual in pop:\n",
    "        preds = sigmoid_function(X @ individual)\n",
    "        cval = cost_func(y, preds, fn_cost)\n",
    "        scores.append(1.0 / (1.0 + cval))\n",
    "    return scores\n",
    "\n",
    "def perform_crossover(parent_a, parent_b):\n",
    "    \"\"\"Single-point crossover at a random index.\"\"\"\n",
    "    point = np.random.randint(len(parent_a))\n",
    "    offspring = np.concatenate([parent_a[:point], parent_b[point:]])\n",
    "    return offspring\n",
    "\n",
    "def perform_mutation(weights, mutation_prob):\n",
    "    \"\"\"\n",
    "    Randomly perturb 'weights' in positions chosen by a Bernoulli mask\n",
    "    with probability 'mutation_prob'.\n",
    "    \"\"\"\n",
    "    mask = np.random.binomial(1, mutation_prob, size=len(weights)).astype(bool)\n",
    "    weights[mask] += (np.random.rand(mask.sum()) - 0.5)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic Algorithm Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_genetic_algorithm(\n",
    "    population_size, \n",
    "    num_iterations, \n",
    "    mutation_probability, \n",
    "    X, \n",
    "    y, \n",
    "    fn_cost, \n",
    "    cost_func\n",
    "):\n",
    "    \"\"\"\n",
    "    - population_size: number of candidate solutions\n",
    "    - num_iterations: GA loop count\n",
    "    - mutation_probability: chance of mutating each gene\n",
    "    - X, y, fn_cost: data\n",
    "    - cost_func: either Bahnsen or Nikou cost function\n",
    "    \n",
    "    Returns: final population and a list of losses per iteration (for plotting).\n",
    "    \"\"\"\n",
    "    # Track cost each iteration\n",
    "    loss_history = []\n",
    "    \n",
    "    # Initialize random population in [-0.5, 0.5]\n",
    "    population = np.random.rand(population_size, X.shape[1]) - 0.5\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Calculate fitness for current population\n",
    "        fitness_scores = calculate_fitness(population, X, y, fn_cost, cost_func)\n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "        \n",
    "        # Probability distribution for selecting parents\n",
    "        prob_dist = fitness_scores / fitness_scores.sum()\n",
    "        \n",
    "        # Choose two parents\n",
    "        idx_a = np.random.choice(range(population_size), p=prob_dist)\n",
    "        idx_b = np.random.choice(range(population_size), p=prob_dist)\n",
    "        \n",
    "        parent_a = population[idx_a]\n",
    "        parent_b = population[idx_b]\n",
    "        \n",
    "        # Create a child\n",
    "        child = perform_crossover(parent_a, parent_b)\n",
    "        child = perform_mutation(child, mutation_probability)\n",
    "        \n",
    "        # Evaluate child fitness\n",
    "        child_score = calculate_fitness([child], X, y, fn_cost, cost_func)[0]\n",
    "        \n",
    "        # Identify worst solution in population\n",
    "        worst_idx = np.argmin(fitness_scores)\n",
    "        \n",
    "        # Identify best solution for logging\n",
    "        best_idx = np.argmax(fitness_scores)\n",
    "        best_solution = population[best_idx]\n",
    "        preds_best = sigmoid_function(X @ best_solution)\n",
    "        current_loss = cost_func(y, preds_best, fn_cost)\n",
    "        loss_history.append(current_loss)\n",
    "        \n",
    "        # Replace worst with child if child is better\n",
    "        if child_score > fitness_scores[worst_idx]:\n",
    "            population[worst_idx] = child\n",
    "    \n",
    "    return population, loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the GA for the Bahnsen Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test cost (Bahnsen approach): 1.8036\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "population_size = 50\n",
    "num_iterations = 300\n",
    "mutation_probability = 0.01\n",
    "\n",
    "final_population, losses_over_epochs = train_genetic_algorithm(\n",
    "    population_size,\n",
    "    num_iterations,\n",
    "    mutation_probability,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cost_train,\n",
    "    cost_bahnsen_approach\n",
    ")\n",
    "\n",
    "# Find the best solution in the final population\n",
    "fitness_scores_final = calculate_fitness(final_population, X_train, y_train, cost_train, cost_bahnsen_approach)\n",
    "best_index = np.argmax(fitness_scores_final)\n",
    "best_solution = final_population[best_index]\n",
    "\n",
    "# Evaluate on test set\n",
    "preds_test = sigmoid_function(X_test @ best_solution)\n",
    "final_test_cost = cost_bahnsen_approach(y_test, preds_test, cost_test)\n",
    "print(f\"Final test cost (Bahnsen approach): {final_test_cost:.4f}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_iterations + 1), losses_over_epochs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Bahnsen Cost\")\n",
    "plt.title(\"Genetic Algorithm: Bahnsen Approach\")\n",
    "plt.savefig(\"bahnsen_plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min cost: 0.000493\n",
      "Max cost: 100000.0\n",
      "Any zero or negative? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Min cost:\", cost_train.min())\n",
    "print(\"Max cost:\", cost_train.max())\n",
    "print(\"Any zero or negative?\", np.any(cost_train <= 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the GA for the Nikou Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3754191/3413150056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmutation_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m final_pop_nikou, nikou_loss_history = train_genetic_algorithm(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3754191/3035123970.py\u001b[0m in \u001b[0;36mtrain_genetic_algorithm\u001b[0;34m(population_size, num_iterations, mutation_probability, X, y, fn_cost, cost_func)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Calculate fitness for current population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mfitness_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mfitness_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3754191/2798183060.py\u001b[0m in \u001b[0;36mcalculate_fitness\u001b[0;34m(pop, X, y, fn_cost, cost_func)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3754191/1950571679.py\u001b[0m in \u001b[0;36mcost_nikou_approach\u001b[0;34m(true_labels, predictions, fn_cost)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Vectorize inverse gamma for the row-specific fn_cost values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mvec_inv_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_inverse_gamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mb_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_inv_gamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_gamma_fpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0ma_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_vals\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2195\u001b[0m                       for a in args]\n\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3754191/2578106789.py\u001b[0m in \u001b[0;36mcompute_inverse_gamma\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Add a small offset to avoid zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     bracket_result = root_scalar(\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mgamma_equation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_root_scalar.py\u001b[0m in \u001b[0;36mroot_scalar\u001b[0;34m(f, args, method, bracket, fprime, fprime2, x0, x1, xtol, rtol, maxiter, options)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'xtol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rtol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run GA for the Nikou cost-sensitive approach\n",
    "population_size = 50\n",
    "num_iterations = 300\n",
    "mutation_probability = 0.01\n",
    "\n",
    "final_pop_nikou, nikou_loss_history = train_genetic_algorithm(\n",
    "    population_size,\n",
    "    num_iterations,\n",
    "    mutation_probability,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cost_train,\n",
    "    cost_nikou_approach  # our Nikou function defined earlier\n",
    ")\n",
    "\n",
    "# Identify the best candidate from the final population\n",
    "fitness_nikou = calculate_fitness(final_pop_nikou, X_train, y_train, cost_train, cost_nikou_approach)\n",
    "fitness_nikou = calculate_fitness(final_pop_nikou, X_train, y_train, cost_train, cost_nikou_approach)\n",
    "best_idx_nikou = np.argmax(fitness_nikou)\n",
    "best_candidate_nikou = final_pop_nikou[best_idx_nikou]\n",
    "\n",
    "# Evaluate on test set using the Nikou approach\n",
    "predictions_test_nikou = sigmoid_function(X_test @ best_candidate_nikou)\n",
    "test_cost_nikou = cost_nikou_approach(y_test, predictions_test_nikou, cost_test)\n",
    "print(f\"Final test cost (Nikou approach): {test_cost_nikou:.4f}\")\n",
    "\n",
    "# Plot the loss evolution for the Nikou approach\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_iterations + 1), nikou_loss_history)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Nikou Cost\")\n",
    "plt.title(\"Genetic Algorithm: Nikou Approach\")\n",
    "plt.savefig(\"nikou_plot.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
